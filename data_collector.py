# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
# !pip install requests beautifulsoup4

import requests
from bs4 import BeautifulSoup # HTML íƒœê·¸ë¥¼ ì œê±°í•˜ê¸° ìœ„í•´ ì‚¬ìš©
from typing import List, Dict
import xml.etree.ElementTree as ET
import pandas as pd
import os
from datetime import datetime, timedelta
import json

def fetch_naver_news(company_name: str, display_count: int = 5) -> List[Dict[str, str]]:
    """
    ë„¤ì´ë²„ ê²€ìƒ‰ APIë¥¼ í˜¸ì¶œí•˜ì—¬ íŠ¹ì • íšŒì‚¬ì˜ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Args:
        company_name (str): ê²€ìƒ‰í•  íšŒì‚¬ ì´ë¦„.
        display_count (int): ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ (ê¸°ë³¸ê°’: 5).

    Returns:
        list[dict]: ë‰´ìŠ¤ ê¸°ì‚¬ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ (ê° ë”•ì…”ë„ˆë¦¬ëŠ” 'title', 'description' í‚¤ë¥¼ í¬í•¨).
    """
    # 1. ë„¤ì´ë²„ ê°œë°œì ì„¼í„°ì—ì„œ ë°œê¸‰ë°›ì€ Client IDì™€ Client Secret
    NAVER_CLIENT_ID = "" # â—€â—€â—€ ë³¸ì¸ì˜ Client IDë¡œ êµì²´
    NAVER_CLIENT_SECRET = "" # â—€â—€â—€ ë³¸ì¸ì˜ Client Secretìœ¼ë¡œ êµì²´
    
    # ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API ì—”ë“œí¬ì¸íŠ¸
    URL = "https://openapi.naver.com/v1/search/news.json"

    # 2. ê²€ìƒ‰ì–´ êµ¬ì²´í™”
    # íšŒì‚¬ ì´ë¦„ë§Œìœ¼ë¡œ ê²€ìƒ‰í•˜ì—¬ ë” ë§ì€ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ë„ë¡ í•©ë‹ˆë‹¤.
    # ë„ˆë¬´ êµ¬ì²´ì ì¸ í‚¤ì›Œë“œëŠ” ê²°ê³¼ ìˆ˜ë¥¼ ì œí•œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    query = f'{company_name}'
    
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET,
    }
    
    params = {
        "query": query,
        "display": display_count,
        "start": 1,  # ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜
        "sort": "date",  # ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬
    }
    
    try:
        response = requests.get(URL, headers=headers, params=params)
        # HTTP ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì˜ˆì™¸ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤.
        response.raise_for_status()
        
        data = response.json()
        articles = []
        
        print(f"ğŸ” API ì‘ë‹µ ì •ë³´: ì´ {data.get('total', 0)}ê±´ ì¤‘ {len(data.get('items', []))}ê±´ ë°˜í™˜")
        
        # 3. ì œëª©ê³¼ ìš”ì•½ì„ í•¨ê»˜ ì¶”ì¶œí•˜ê³ , HTML íƒœê·¸ ì œê±°
        for item in data.get('items', []):
            # BeautifulSoupì„ ì‚¬ìš©í•´ ì œëª©ì—ì„œ <b>, </b>, &quot; ë“± HTML íƒœê·¸ ì œê±°
            raw_title = item.get('title', '')
            cleaned_title = BeautifulSoup(raw_title, "html.parser").get_text()
            
            # ìš”ì•½ ë‚´ìš©(description)ì—ì„œë„ HTML íƒœê·¸ ì œê±°
            raw_desc = item.get('description', '')
            cleaned_desc = BeautifulSoup(raw_desc, "html.parser").get_text()
            
            articles.append({"title": cleaned_title, "description": cleaned_desc})
        
        print(f"âœ… ë„¤ì´ë²„ ë‰´ìŠ¤ API í˜¸ì¶œ ì„±ê³µ: '{company_name}' ê´€ë ¨ ë‰´ìŠ¤ {len(articles)}ê±´ ìˆ˜ì§‘")
        return articles

    # 4. ì—ëŸ¬ ì²˜ë¦¬
    except requests.exceptions.HTTPError as http_err:
        print(f"HTTP ì—ëŸ¬ ë°œìƒ: {http_err} - ì‘ë‹µ ë©”ì‹œì§€: {response.text}")
        if response.status_code == 401:
            print(">> ì¸ì¦ ì˜¤ë¥˜: Client IDì™€ Secretì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        elif response.status_code == 429:
            print(">> API í˜¸ì¶œ í•œë„ ì´ˆê³¼: ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
    except Exception as e:
        print(f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        
    return []

def load_corp_codes(xml_path='CORPCODE.xml'):
    """
    CORPCODE.xml íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ëª¨ë“  íšŒì‚¬ëª…ê³¼ ê³ ìœ ë²ˆí˜¸ë¥¼
    pandas DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        xml_path (str): CORPCODE.xml íŒŒì¼ì˜ ê²½ë¡œ.

    Returns:
        pandas.DataFrame: 'corp_name'ê³¼ 'corp_code' ì»¬ëŸ¼ì„ ê°€ì§„ DataFrame.
                          íŒŒì¼ì„ ì°¾ì§€ ëª»í•˜ë©´ Noneì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        # XML íŒŒì¼ íŒŒì‹±
        tree = ET.parse(xml_path)
        root = tree.getroot()
        
        corp_list = []
        # XMLì˜ 'list' íƒœê·¸ë¥¼ ëª¨ë‘ ì°¾ì•„ì„œ ë°˜ë³µí•©ë‹ˆë‹¤.
        for corp in root.findall('list'):
            # ê° íƒœê·¸ì—ì„œ í…ìŠ¤íŠ¸ ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
            corp_name = corp.find('corp_name').text
            corp_code = corp.find('corp_code').text
            
            # ë¦¬ìŠ¤íŠ¸ì— ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì¶”ê°€
            corp_list.append({
                'corp_name': corp_name,
                'corp_code': corp_code
            })
            
        # ë¦¬ìŠ¤íŠ¸ë¥¼ pandas DataFrameìœ¼ë¡œ ë³€í™˜
        df = pd.DataFrame(corp_list)
        print(f"âœ… ì´ {len(df)}ê°œì˜ ìƒì¥ ê¸°ì—… ì •ë³´ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        return df

    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: '{xml_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return None
    except Exception as e:
        print(f"XML íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def find_corp_code(company_name, corp_code_df):
    """
    DataFrameì—ì„œ íšŒì‚¬ëª…ìœ¼ë¡œ ê³ ìœ ë²ˆí˜¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

    Args:
        company_name (str): ì°¾ê³  ì‹¶ì€ íšŒì‚¬ì˜ ì •í™•í•œ ì „ì²´ ì´ë¦„.
        corp_code_df (pandas.DataFrame): load_corp_codes í•¨ìˆ˜ë¡œ ìƒì„±ëœ DataFrame.

    Returns:
        str | None: íšŒì‚¬ì˜ 8ìë¦¬ ê³ ìœ ë²ˆí˜¸ ë˜ëŠ” ì°¾ì§€ ëª»í–ˆì„ ê²½ìš° None.
    """
    if corp_code_df is None:
        return None
        
    # 'corp_name' ì»¬ëŸ¼ì—ì„œ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” íšŒì‚¬ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    result = corp_code_df[corp_code_df['corp_name'] == company_name]
    
    if not result.empty:
        # ì°¾ì€ ê²½ìš°, ì²« ë²ˆì§¸ ê²°ê³¼ì˜ 'corp_code' ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        return result.iloc[0]['corp_code']
    else:
        print(f"'{company_name}'ì— í•´ë‹¹í•˜ëŠ” íšŒì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None


def load_corp_codes_optimized(xml_path='CORPCODE.xml', csv_path='corp_codes.csv', force_refresh=False):
    """
    CORPCODE.xml íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ CSVë¡œ ìºì‹±í•˜ê³ , ë‹¤ìŒë¶€í„°ëŠ” CSVë¥¼ ì½ì–´ì„œ ë¹ ë¥´ê²Œ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        xml_path (str): CORPCODE.xml íŒŒì¼ì˜ ê²½ë¡œ (ê¸°ë³¸ê°’: 'CORPCODE.xml').
        csv_path (str): ìºì‹œìš© CSV íŒŒì¼ì˜ ê²½ë¡œ (ê¸°ë³¸ê°’: 'corp_codes.csv').
        force_refresh (bool): Trueë©´ ê¸°ì¡´ CSVë¥¼ ë¬´ì‹œí•˜ê³  XMLì„ ë‹¤ì‹œ íŒŒì‹± (ê¸°ë³¸ê°’: False).
    
    Returns:
        pandas.DataFrame: 'corp_name'ê³¼ 'corp_code' ì»¬ëŸ¼ì„ ê°€ì§„ DataFrame.
    """
    
    # 1. force_refreshê°€ Falseì´ê³  CSV íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ CSVì—ì„œ ë°”ë¡œ ë¡œë“œ
    if not force_refresh and os.path.exists(csv_path):
        try:
            print(f"âš¡ ê¸°ì¡´ CSV íŒŒì¼ì—ì„œ ë¹ ë¥´ê²Œ ë¡œë“œí•©ë‹ˆë‹¤: {csv_path}")
            start_time = datetime.now()
            
            df = pd.read_csv(csv_path)
            
            end_time = datetime.now()
            load_time = (end_time - start_time).total_seconds()
            
            print(f"âœ… CSV ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ê¸°ì—… ì •ë³´ ({load_time:.2f}ì´ˆ)")
            return df
            
        except Exception as e:
            print(f"âš ï¸ CSV íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            print("XML íŒŒì¼ì—ì„œ ë‹¤ì‹œ íŒŒì‹±í•©ë‹ˆë‹¤...")
    
    # 2. XML íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ì˜¤ë¥˜ ë°˜í™˜
    if not os.path.exists(xml_path):
        print(f"âŒ '{xml_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # 3. XML íŒŒì‹± (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼)
    try:
        print(f"ğŸ”„ XML íŒŒì‹± ì‹œì‘: {xml_path} (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤...)")
        start_time = datetime.now()
        
        tree = ET.parse(xml_path)
        root = tree.getroot()
        
        corp_list = []
        total_corps = len(root.findall('list'))
        
        for i, corp in enumerate(root.findall('list'), 1):
            corp_name = corp.find('corp_name').text
            corp_code = corp.find('corp_code').text
            
            corp_list.append({
                'corp_name': corp_name,
                'corp_code': corp_code
            })
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ (10000ê°œë§ˆë‹¤)
            if i % 10000 == 0:
                print(f"  íŒŒì‹± ì§„í–‰: {i:,}/{total_corps:,} ({i/total_corps*100:.1f}%)")
        
        df = pd.DataFrame(corp_list)
        
        end_time = datetime.now()
        parse_time = (end_time - start_time).total_seconds()
        
        print(f"âœ… XML íŒŒì‹± ì™„ë£Œ: {len(df)}ê°œ ê¸°ì—… ì •ë³´ ({parse_time:.2f}ì´ˆ)")
        
        # 4. CSVë¡œ ì €ì¥ (ë‹¤ìŒë²ˆì— ë¹ ë¥´ê²Œ ë¡œë“œí•˜ê¸° ìœ„í•´)
        try:
            print(f"ğŸ’¾ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤: {csv_path}")
            df.to_csv(csv_path, index=False, encoding='utf-8-sig')  # BOM ì¶”ê°€ë¡œ í•œê¸€ í˜¸í™˜ì„± í–¥ìƒ
            print(f"âœ… CSV ì €ì¥ ì™„ë£Œ. ë‹¤ìŒë¶€í„°ëŠ” ë¹ ë¥´ê²Œ ë¡œë“œë©ë‹ˆë‹¤!")
        except Exception as e:
            print(f"âš ï¸ CSV ì €ì¥ ì‹¤íŒ¨: {e} (ê¸°ëŠ¥ì€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤)")
        
        return df
        
    except Exception as e:
        print(f"âŒ XML íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def get_corp_info_fast(company_name, csv_path='corp_codes.csv'):
    """
    ë¹ ë¥¸ íšŒì‚¬ ì •ë³´ ì¡°íšŒ í•¨ìˆ˜. CSV íŒŒì¼ì—ì„œ ë°”ë¡œ íšŒì‚¬ ì •ë³´ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    
    Args:
        company_name (str): ì°¾ê³  ì‹¶ì€ íšŒì‚¬ëª….
        csv_path (str): CSV íŒŒì¼ ê²½ë¡œ.
        
    Returns:
        dict | None: {'corp_name': íšŒì‚¬ëª…, 'corp_code': ê³ ìœ ë²ˆí˜¸} ë˜ëŠ” None.
    """
    if not os.path.exists(csv_path):
        print(f"âŒ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
        print("ë¨¼ì € load_corp_codes_optimized() í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return None
    
    try:
        # CSVì—ì„œ íŠ¹ì • íšŒì‚¬ë§Œ ê²€ìƒ‰ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
        # corp_codeë¥¼ ë¬¸ìì—´ë¡œ ì½ì–´ì„œ ì•ì˜ 0ì´ ì œê±°ë˜ì§€ ì•Šë„ë¡ í•¨
        df = pd.read_csv(csv_path, dtype={'corp_code': str})
        result = df[df['corp_name'] == company_name]
        
        if not result.empty:
            corp_code = result.iloc[0]['corp_code']
            # 8ìë¦¬ í˜•ì‹ìœ¼ë¡œ ë³´ì¥ (DART API ìš”êµ¬ì‚¬í•­)
            corp_code = str(corp_code).zfill(8)
            return {
                'corp_name': result.iloc[0]['corp_name'],
                'corp_code': corp_code
            }
        else:
            return None
            
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return None


def search_companies_by_keyword(keyword, csv_path='corp_codes.csv', max_results=20):
    """
    í‚¤ì›Œë“œë¡œ íšŒì‚¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        keyword (str): ê²€ìƒ‰í•  í‚¤ì›Œë“œ.
        csv_path (str): CSV íŒŒì¼ ê²½ë¡œ.
        max_results (int): ìµœëŒ€ ê²°ê³¼ ê°œìˆ˜.
        
    Returns:
        pandas.DataFrame: ê²€ìƒ‰ ê²°ê³¼ DataFrame.
    """
    if not os.path.exists(csv_path):
        print(f"âŒ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
        return pd.DataFrame()
    
    try:
        df = pd.read_csv(csv_path)
        results = df[df['corp_name'].str.contains(keyword, na=False)]
        
        if len(results) > max_results:
            print(f"ğŸ” '{keyword}' ê²€ìƒ‰ê²°ê³¼: {len(results)}ê°œ (ìƒìœ„ {max_results}ê°œë§Œ í‘œì‹œ)")
            return results.head(max_results)
        else:
            print(f"ğŸ” '{keyword}' ê²€ìƒ‰ê²°ê³¼: {len(results)}ê°œ")
            return results
            
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()


def fetch_dart_disclosures(corp_code, start_date=None, end_date=None, page_no=1, page_count=10):
    """
    DART APIë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • íšŒì‚¬ì˜ ê³µì‹œ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Args:
        corp_code (str): 8ìë¦¬ íšŒì‚¬ ê³ ìœ ë²ˆí˜¸.
        start_date (str): ê²€ìƒ‰ ì‹œì‘ì¼ (YYYYMMDD í˜•ì‹, ê¸°ë³¸ê°’: 30ì¼ ì „).
        end_date (str): ê²€ìƒ‰ ì¢…ë£Œì¼ (YYYYMMDD í˜•ì‹, ê¸°ë³¸ê°’: ì˜¤ëŠ˜).
        page_no (int): í˜ì´ì§€ ë²ˆí˜¸ (ê¸°ë³¸ê°’: 1).
        page_count (int): í˜ì´ì§€ë‹¹ ê±´ìˆ˜ (ê¸°ë³¸ê°’: 10, ìµœëŒ€ 100).
        
    Returns:
        List[Dict]: ê³µì‹œ ì •ë³´ ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸.
    """
    
    # DART API í‚¤ (ë¬´ë£Œ API í‚¤ ë°œê¸‰ í•„ìš”: https://opendart.fss.or.kr/)
    DART_API_KEY = ""  # â—€â—€â—€ ì‹¤ì œ API í‚¤ë¡œ êµì²´ í•„ìš”!
    
    # ê³ ìœ ë²ˆí˜¸ë¥¼ 8ìë¦¬ í˜•ì‹ìœ¼ë¡œ ë³´ì¥
    corp_code = str(corp_code).zfill(8)
    
    # ê¸°ë³¸ ë‚ ì§œ ì„¤ì • (30ì¼ ì „ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€)
    if not end_date:
        end_date = datetime.now().strftime('%Y%m%d')
    if not start_date:
        start_date = (datetime.now() - timedelta(days=30)).strftime('%Y%m%d')
    
    # DART API ì—”ë“œí¬ì¸íŠ¸
    url = "https://opendart.fss.or.kr/api/list.json"
    
    params = {
        'crtfc_key': DART_API_KEY,
        'corp_code': corp_code,
        'bgn_de': start_date,
        'end_de': end_date,
        'page_no': page_no,
        'page_count': min(page_count, 100)  # ìµœëŒ€ 100ê±´ìœ¼ë¡œ ì œí•œ
    }
    
    try:
        print(f"ğŸ” DART API í˜¸ì¶œ: {corp_code} ({start_date}~{end_date})")
        
        response = requests.get(url, params=params)
        response.raise_for_status()
        
        data = response.json()
        
        # API ì‘ë‹µ ìƒíƒœ í™•ì¸
        if data.get('status') != '000':
            error_message = data.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
            print(f"âŒ DART API ì˜¤ë¥˜: {error_message}")
            return []
        
        # ê³µì‹œ ëª©ë¡ ì¶”ì¶œ
        disclosures = data.get('list', [])
        
        if disclosures:
            print(f"âœ… DART ê³µì‹œ ì •ë³´ {len(disclosures)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
            
            # í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œí•˜ì—¬ ì •ë¦¬
            cleaned_disclosures = []
            for item in disclosures:
                cleaned_item = {
                    'corp_name': item.get('corp_name', ''),
                    'report_nm': item.get('report_nm', ''),  # ë³´ê³ ì„œëª…
                    'rcept_no': item.get('rcept_no', ''),    # ì ‘ìˆ˜ë²ˆí˜¸
                    'flr_nm': item.get('flr_nm', ''),        # ê³µì‹œì œì¶œì¸ëª…
                    'rcept_dt': item.get('rcept_dt', ''),    # ì ‘ìˆ˜ì¼ì
                    'rm': item.get('rm', '')                 # ë¹„ê³ 
                }
                cleaned_disclosures.append(cleaned_item)
            
            return cleaned_disclosures
        else:
            print(f"ğŸ“­ í•´ë‹¹ ê¸°ê°„ì— ê³µì‹œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
            
    except requests.exceptions.RequestException as e:
        print(f"âŒ DART API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return []
    except Exception as e:
        print(f"âŒ ê³µì‹œ ì •ë³´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return []


def get_company_disclosures_by_name(company_name, csv_path='corp_codes.csv', days_back=30, max_count=10):
    """
    íšŒì‚¬ëª…ìœ¼ë¡œ ìµœê·¼ ê³µì‹œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í†µí•© í•¨ìˆ˜.
    
    Args:
        company_name (str): íšŒì‚¬ëª….
        csv_path (str): CSV íŒŒì¼ ê²½ë¡œ.
        days_back (int): ì¡°íšŒí•  ê³¼ê±° ì¼ìˆ˜ (ê¸°ë³¸ê°’: 30ì¼).
        max_count (int): ìµœëŒ€ ê³µì‹œ ê±´ìˆ˜ (ê¸°ë³¸ê°’: 10ê±´).
        
    Returns:
        List[Dict]: ê³µì‹œ ì •ë³´ ë¦¬ìŠ¤íŠ¸.
    """
    
    print(f"=== {company_name} ê³µì‹œ ì •ë³´ ì¡°íšŒ ===")
    
    # 1ë‹¨ê³„: íšŒì‚¬ëª…ìœ¼ë¡œ ê³ ìœ ë²ˆí˜¸ ì°¾ê¸°
    corp_info = get_corp_info_fast(company_name, csv_path)
    
    if not corp_info:
        print(f"âŒ '{company_name}' íšŒì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    corp_code = corp_info['corp_code']
    print(f"âœ… íšŒì‚¬ ì •ë³´: {corp_info['corp_name']} ({corp_code})")
    
    # 2ë‹¨ê³„: DART APIë¡œ ê³µì‹œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    start_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y%m%d')
    end_date = datetime.now().strftime('%Y%m%d')
    
    disclosures = fetch_dart_disclosures(
        corp_code=corp_code,
        start_date=start_date,
        end_date=end_date,
        page_count=max_count
    )
    
    return disclosures


def format_disclosures_for_llm(disclosures, company_name):
    """
    ê³µì‹œ ì •ë³´ë¥¼ LLMì´ ë¶„ì„í•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
    
    Args:
        disclosures (List[Dict]): ê³µì‹œ ì •ë³´ ë¦¬ìŠ¤íŠ¸.
        company_name (str): íšŒì‚¬ëª….
        
    Returns:
        str: í¬ë§·íŒ…ëœ ê³µì‹œ ì •ë³´ í…ìŠ¤íŠ¸.
    """
    
    if not disclosures:
        return f"### {company_name} ìµœê·¼ ê³µì‹œ ì •ë³´\n- ìµœê·¼ 30ì¼ê°„ ê³µì‹œëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    formatted_text = f"### {company_name} ìµœê·¼ ê³µì‹œ ì •ë³´\n"
    
    for i, disclosure in enumerate(disclosures, 1):
        # ë‚ ì§œ í¬ë§·íŒ… (YYYYMMDD -> YYYY-MM-DD)
        rcept_dt = disclosure.get('rcept_dt', '')
        if len(rcept_dt) == 8:
            formatted_date = f"{rcept_dt[:4]}-{rcept_dt[4:6]}-{rcept_dt[6:8]}"
        else:
            formatted_date = rcept_dt
        
        report_nm = disclosure.get('report_nm', 'ì œëª© ì—†ìŒ')
        flr_nm = disclosure.get('flr_nm', 'ì œì¶œì¸ ë¯¸ìƒ')
        rm = disclosure.get('rm', '')
        
        formatted_text += f"\n**{i}. {report_nm}**\n"
        formatted_text += f"   - ì œì¶œì¼: {formatted_date}\n"
        formatted_text += f"   - ì œì¶œì¸: {flr_nm}\n"
        
        if rm:
            formatted_text += f"   - ë¹„ê³ : {rm}\n"
    
    return formatted_text


def get_important_disclosures_by_priority(company_name, csv_path='corp_codes.csv', days_back=90):
    """
    ì¤‘ìš”ë„ë³„ë¡œ ë¶„ë¥˜ëœ ê³µì‹œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜.
    
    Args:
        company_name (str): íšŒì‚¬ëª….
        csv_path (str): CSV íŒŒì¼ ê²½ë¡œ.
        days_back (int): ì¡°íšŒí•  ê³¼ê±° ì¼ìˆ˜ (ê¸°ë³¸ê°’: 90ì¼).
        
    Returns:
        dict: ì¤‘ìš”ë„ë³„ë¡œ ë¶„ë¥˜ëœ ê³µì‹œ ì •ë³´.
    """
    
    print(f"=== {company_name} ì¤‘ìš” ê³µì‹œ ì •ë³´ ë¶„ì„ ===")
    
    # 1. ì „ì²´ ê³µì‹œ ê°€ì ¸ì˜¤ê¸° (ë” ë§ì€ ë°ì´í„°ë¥¼ ìœ„í•´ 90ì¼, ìµœëŒ€ 100ê±´)
    all_disclosures = get_company_disclosures_by_name(
        company_name, csv_path, days_back=days_back, max_count=100
    )
    
    if not all_disclosures:
        return {
            'priority_1': [], 'priority_2': [], 'priority_3': [], 'risk_signals': []
        }
    
    # 2. ì¤‘ìš”ë„ë³„ í‚¤ì›Œë“œ ì •ì˜
    keywords = {
        'priority_1': {
            'ì •ê¸°ë³´ê³ ì„œ': ['ì‚¬ì—…ë³´ê³ ì„œ', 'ë¶„ê¸°ë³´ê³ ì„œ', 'ë°˜ê¸°ë³´ê³ ì„œ'],
            'ì‹¤ì ê³µì‹œ': ['ì˜ì—…ì‹¤ì ', 'ì ì •ì‹¤ì ', 'ì—°ê²°ì‹¤ì ', 'ë³„ë„ì‹¤ì ']
        },
        'priority_2': {
            'M&A_íˆ¬ì': ['íƒ€ë²•ì¸ì£¼ì‹', 'íƒ€ë²•ì¸ ì£¼ì‹', 'ì¶œìì¦ê¶Œ', 'ì§€ë¶„ì·¨ë“', 'ì§€ë¶„ì²˜ë¶„'],
            'ì¦ì': ['ìœ ìƒì¦ì', 'ë¬´ìƒì¦ì', 'ì‹ ì£¼ë°œí–‰'],
            'ìì‚¬ì£¼': ['ìê¸°ì£¼ì‹ì·¨ë“', 'ìê¸°ì£¼ì‹ì²˜ë¶„', 'ìì‚¬ì£¼ë§¤ì…']
        },
        'priority_3': {
            'ê³„ì•½ìˆ˜ì£¼': ['ë‹¨ì¼íŒë§¤', 'ê³µê¸‰ê³„ì•½', 'ê³„ì•½ì²´ê²°', 'ìˆ˜ì£¼'],
            'íˆ¬ìí™•ì¥': ['ì‹ ê·œì‹œì„¤íˆ¬ì', 'ì„¤ë¹„íˆ¬ì', 'íˆ¬ìê²°ì •']
        },
        'risk_signals': {
            'ì§€ë°°êµ¬ì¡°': ['ìµœëŒ€ì£¼ì£¼ë³€ê²½', 'ì£¼ì£¼ë³€ê²½'],
            'ë²•ì ë¦¬ìŠ¤í¬': ['ì†Œì†¡ì œê¸°', 'ì†Œì†¡ì‹ ì²­', 'ë¶„ìŸ']
        }
    }
    
    # 3. ê³µì‹œë¥¼ ì¤‘ìš”ë„ë³„ë¡œ ë¶„ë¥˜
    classified_disclosures = {
        'priority_1': [],
        'priority_2': [],
        'priority_3': [],
        'risk_signals': []
    }
    
    for disclosure in all_disclosures:
        report_name = disclosure.get('report_nm', '').lower()
        classified = False
        
        # ê° ìš°ì„ ìˆœìœ„ë³„ë¡œ í‚¤ì›Œë“œ ë§¤ì¹­
        for priority, categories in keywords.items():
            if classified:
                break
                
            for category, keyword_list in categories.items():
                if any(keyword.lower() in report_name for keyword in keyword_list):
                    disclosure['category'] = category
                    classified_disclosures[priority].append(disclosure)
                    classified = True
                    break
    
    # 4. ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ“Š ì¤‘ìš” ê³µì‹œ ë¶„ë¥˜ ê²°ê³¼:")
    print(f"  ğŸ† 1ìˆœìœ„ (ì‹¤ì /ë³´ê³ ì„œ): {len(classified_disclosures['priority_1'])}ê±´")
    print(f"  ğŸš€ 2ìˆœìœ„ (ì¤‘ëŒ€ê²°ì •): {len(classified_disclosures['priority_2'])}ê±´") 
    print(f"  ğŸ“ˆ 3ìˆœìœ„ (ì‚¬ì—…íë¦„): {len(classified_disclosures['priority_3'])}ê±´")
    print(f"  âš ï¸ ë¦¬ìŠ¤í¬ ì‹ í˜¸: {len(classified_disclosures['risk_signals'])}ê±´")
    
    return classified_disclosures


def format_date(date_str):
    """ë‚ ì§œ í¬ë§·íŒ… í—¬í¼ í•¨ìˆ˜ (YYYYMMDD -> YYYY-MM-DD)"""
    if len(date_str) == 8:
        return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
    return date_str


def format_priority_disclosures_for_llm(classified_disclosures, company_name):
    """
    ì¤‘ìš”ë„ë³„ë¡œ ë¶„ë¥˜ëœ ê³µì‹œ ì •ë³´ë¥¼ LLMìš©ìœ¼ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
    
    Args:
        classified_disclosures (dict): ë¶„ë¥˜ëœ ê³µì‹œ ì •ë³´.
        company_name (str): íšŒì‚¬ëª….
        
    Returns:
        str: í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸.
    """
    
    formatted_text = f"### {company_name} ì¤‘ìš” ê³µì‹œ ë¶„ì„\n"
    
    # 1ìˆœìœ„: ì‹¤ì ê³¼ ì§ê²°ëœ ì •ë³´
    if classified_disclosures['priority_1']:
        formatted_text += "\n#### ğŸ† í•µì‹¬ ì‹¤ì  ì •ë³´\n"
        for disclosure in classified_disclosures['priority_1']:
            date = format_date(disclosure.get('rcept_dt', ''))
            report = disclosure.get('report_nm', '')
            category = disclosure.get('category', '')
            
            formatted_text += f"- **{report}** ({date})\n"
            formatted_text += f"  âœ“ ë¶„ë¥˜: {category}\n"
    
    # 2ìˆœìœ„: ì¤‘ëŒ€í•œ ê²½ì˜ ê²°ì •
    if classified_disclosures['priority_2']:
        formatted_text += "\n#### ğŸš€ ì£¼ìš” ê²½ì˜ ê²°ì •\n"
        for disclosure in classified_disclosures['priority_2']:
            date = format_date(disclosure.get('rcept_dt', ''))
            report = disclosure.get('report_nm', '')
            category = disclosure.get('category', '')
            
            formatted_text += f"- **{report}** ({date})\n"
            formatted_text += f"  âœ“ ë¶„ë¥˜: {category}\n"
    
    # 3ìˆœìœ„: ì‚¬ì—… íë¦„
    if classified_disclosures['priority_3']:
        formatted_text += "\n#### ğŸ“ˆ ì‚¬ì—… ë™í–¥\n"
        for disclosure in classified_disclosures['priority_3']:
            date = format_date(disclosure.get('rcept_dt', ''))
            report = disclosure.get('report_nm', '')
            category = disclosure.get('category', '')
            
            formatted_text += f"- **{report}** ({date})\n"
            formatted_text += f"  âœ“ ë¶„ë¥˜: {category}\n"
    
    # ë¦¬ìŠ¤í¬ ì‹ í˜¸
    if classified_disclosures['risk_signals']:
        formatted_text += "\n#### âš ï¸ ì£¼ì˜ ì‚¬í•­\n"
        for disclosure in classified_disclosures['risk_signals']:
            date = format_date(disclosure.get('rcept_dt', ''))
            report = disclosure.get('report_nm', '')
            category = disclosure.get('category', '')
            
            formatted_text += f"- **{report}** ({date})\n"
            formatted_text += f"  âœ“ ë¦¬ìŠ¤í¬ ìš”ì¸: {category}\n"
    
    # ë¶„ì„ì´ ì—†ëŠ” ê²½ìš°
    total_important = sum(len(v) for v in classified_disclosures.values())
    if total_important == 0:
        formatted_text += "\n- ìµœê·¼ 90ì¼ê°„ ì£¼ìš” ê³µì‹œê°€ ì—†ìŠµë‹ˆë‹¤.\n"
    
    return formatted_text


def create_smart_company_report(company_name, csv_path='corp_codes.csv'):
    """
    ë‰´ìŠ¤ + ì¤‘ìš”ë„ë³„ ê³µì‹œ ì •ë³´ë¥¼ ê²°í•©í•œ ìŠ¤ë§ˆíŠ¸ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        company_name (str): íšŒì‚¬ëª….
        csv_path (str): CSV íŒŒì¼ ê²½ë¡œ.
        
    Returns:
        str: LLMìš© ìŠ¤ë§ˆíŠ¸ ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°.
    """
    
    print(f"=== {company_name} ìŠ¤ë§ˆíŠ¸ ë¦¬í¬íŠ¸ ìƒì„± ===")
    
    # 1. ë‰´ìŠ¤ ì •ë³´ ìˆ˜ì§‘
    print("\n1. ìµœì‹  ë‰´ìŠ¤ ìˆ˜ì§‘...")
    news_articles = fetch_naver_news(company_name, display_count=5)
    
    news_context = ""
    if news_articles:
        filtered_headlines = []
        for article in news_articles:
            if company_name in article['title'] or company_name in article['description']:
                filtered_headlines.append(article['title'])
        
        if filtered_headlines:
            news_context = f"### {company_name} ìµœì‹  ë‰´ìŠ¤\n"
            news_context += "- " + "\n- ".join(filtered_headlines) + "\n"
    
    # 2. ì¤‘ìš”ë„ë³„ ê³µì‹œ ì •ë³´ ìˆ˜ì§‘
    print("\n2. ì¤‘ìš” ê³µì‹œ ë¶„ì„...")
    classified_disclosures = get_important_disclosures_by_priority(company_name, csv_path)
    disclosure_context = format_priority_disclosures_for_llm(classified_disclosures, company_name)
    
    # 3. ìŠ¤ë§ˆíŠ¸ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    smart_context = f"""
{news_context}

{disclosure_context}

---
â€» ë¶„ì„ ê¸°ì¤€: 
- ë‰´ìŠ¤: ìµœì‹  5ê±´ ì¤‘ ê´€ë ¨ ë‰´ìŠ¤
- ê³µì‹œ: ìµœê·¼ 90ì¼ ì¤‘ìš” ê³µì‹œë§Œ ì„ ë³„ ë¶„ì„
- ë¶„ë¥˜: ì‹¤ì ì •ë³´ > ê²½ì˜ê²°ì • > ì‚¬ì—…ë™í–¥ > ë¦¬ìŠ¤í¬ì‹ í˜¸
"""
    
    print("\nâœ… ìŠ¤ë§ˆíŠ¸ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“ˆ ì´ ì¤‘ìš” ê³µì‹œ: {sum(len(v) for v in classified_disclosures.values())}ê±´")
    
    return smart_context


def create_final_investment_report(company_name, csv_path='corp_codes.csv'):
    """
    ìµœì¢… íˆ¬ì ë¦¬í¬íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ëŠ” í•¨ìˆ˜.
    ë‰´ìŠ¤ + ì¤‘ìš”ë„ë³„ ê³µì‹œ + LLM ë¶„ì„ì„ ê²°í•©í•©ë‹ˆë‹¤.
    
    Args:
        company_name (str): íšŒì‚¬ëª….
        csv_path (str): CSV íŒŒì¼ ê²½ë¡œ.
        
    Returns:
        dict: ìµœì¢… ë¦¬í¬íŠ¸ ë°ì´í„° (ì»¨í…ìŠ¤íŠ¸ + í”„ë¡¬í”„íŠ¸).
    """
    
    print(f"ğŸ¯ {company_name} ìµœì¢… íˆ¬ì ë¦¬í¬íŠ¸ ìë™ ìƒì„± ì‹œì‘")
    print("="*60)
    
    # 1. ìŠ¤ë§ˆíŠ¸ ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    smart_context = create_smart_company_report(company_name, csv_path)
    
    # 2. ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±
    final_prompt = f"""
# ì§€ì‹œë¬¸: ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ì¦ê¶Œì‚¬ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ [ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°]ë§Œì„ ì‚¬ìš©í•˜ì—¬, '{company_name}'ì— ëŒ€í•œ íˆ¬ì ë¦¬í¬íŠ¸ë¥¼ ë‹¤ìŒ [ë¦¬í¬íŠ¸ í˜•ì‹]ì— ë§ì¶° ì‘ì„±í•´ ì£¼ì„¸ìš”. ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.

# ë¦¬í¬íŠ¸ í˜•ì‹
## 1. **íˆ¬ì í¬ì¸íŠ¸ ìš”ì•½ (Investment Highlights)**
- ìµœì‹  ë‰´ìŠ¤ì™€ ê³µì‹œë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ í•µì‹¬ íˆ¬ì í¬ì¸íŠ¸ 3ê°€ì§€

## 2. **ì‹¤ì  ë° ê²½ì˜ í˜„í™© ë¶„ì„**
- ğŸ† ìµœê·¼ ì‹¤ì  ì •ë³´ ë¶„ì„ (ë¶„ê¸°/ë°˜ê¸° ë³´ê³ ì„œ, ì˜ì—…ì‹¤ì  ê¸°ì¤€)
- ğŸš€ ì£¼ìš” ê²½ì˜ ê²°ì • ë¶„ì„ (M&A, ì¦ì, ìì‚¬ì£¼ ë“±)

## 3. **ì‚¬ì—… ë™í–¥ ë° ì„±ì¥ ë™ë ¥**
- ğŸ“ˆ ì‹ ê·œ ê³„ì•½, íˆ¬ì í™•ì¥ ë“± ë¯¸ë˜ ì„±ì¥ ìš”ì¸ ë¶„ì„
- ì‹œì¥ì—ì„œì˜ ê²½ìŸë ¥ê³¼ í¬ì§€ì…”ë‹

## 4. **ë¦¬ìŠ¤í¬ ìš”ì¸**
- âš ï¸ ì£¼ì˜í•´ì•¼ í•  ìœ„í—˜ ìš”ì†Œ (ì†Œì†¡, ì§€ë°°êµ¬ì¡° ë³€í™” ë“±)
- ë‹¨ê¸°/ì¤‘ê¸°ì  ìš°ë ¤ ì‚¬í•­

## 5. **ì¢…í•© íˆ¬ì ì˜ê²¬**
- ìœ„ ë¶„ì„ì„ ì¢…í•©í•œ íˆ¬ì ê´€ì ì—ì„œì˜ ìµœì¢… ì˜ê²¬
- ëª©í‘œ ì£¼ê°€ë‚˜ êµ¬ì²´ì  ìˆ˜ì¹˜ ì œì‹œ ê¸ˆì§€ (ì •ì„±ì  í‰ê°€ë§Œ)

# ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°
{smart_context}

---
â€» ì£¼ì˜ì‚¬í•­: ìœ„ ë°ì´í„°ì— í¬í•¨ë˜ì§€ ì•Šì€ ì •ë³´ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
"""
    
    print("\nğŸ¯ ìµœì¢… ë¦¬í¬íŠ¸ êµ¬ì„± ìš”ì†Œ:")
    print("  ğŸ“° ìµœì‹  ë‰´ìŠ¤ ë¶„ì„")
    print("  ğŸ† í•µì‹¬ ì‹¤ì  ì •ë³´")
    print("  ğŸš€ ì£¼ìš” ê²½ì˜ ê²°ì •") 
    print("  ğŸ“ˆ ì‚¬ì—… ë™í–¥")
    print("  âš ï¸ ë¦¬ìŠ¤í¬ ìš”ì¸")
    print("\nâœ… ìµœì¢… íˆ¬ì ë¦¬í¬íŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ!")
    
    return {
        'company_name': company_name,
        'context_data': smart_context,
        'final_prompt': final_prompt,
        'generation_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }


def create_comprehensive_company_report(company_name, csv_path='corp_codes.csv'):
    """
    ë‰´ìŠ¤ + ê³µì‹œ ì •ë³´ë¥¼ ê²°í•©í•œ ì¢…í•© íšŒì‚¬ ë¦¬í¬íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    (ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
    
    Args:
        company_name (str): íšŒì‚¬ëª….
        csv_path (str): CSV íŒŒì¼ ê²½ë¡œ.
        
    Returns:
        str: LLMìš© ì¢…í•© ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°.
    """
    
    print(f"=== {company_name} ì¢…í•© ë¦¬í¬íŠ¸ ë°ì´í„° ìƒì„± ===")
    
    # 1. ë‰´ìŠ¤ ì •ë³´ ìˆ˜ì§‘
    print("\n1. ë‰´ìŠ¤ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
    news_articles = fetch_naver_news(company_name, display_count=5)
    
    news_context = ""
    if news_articles:
        filtered_headlines = []
        for article in news_articles:
            if company_name in article['title'] or company_name in article['description']:
                filtered_headlines.append(article['title'])
        
        if filtered_headlines:
            news_context = f"### {company_name} ìµœì‹  ë‰´ìŠ¤\n"
            news_context += "- " + "\n- ".join(filtered_headlines) + "\n"
    
    # 2. ê³µì‹œ ì •ë³´ ìˆ˜ì§‘
    print("\n2. ê³µì‹œ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
    disclosures = get_company_disclosures_by_name(company_name, csv_path, days_back=30, max_count=10)
    disclosure_context = format_disclosures_for_llm(disclosures, company_name)
    
    # 3. ì¢…í•© ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    comprehensive_context = f"""
{news_context}

{disclosure_context}

---
â€» ë°ì´í„° ê¸°ì¤€: ë‰´ìŠ¤(ìµœì‹  5ê±´), ê³µì‹œ(ìµœê·¼ 30ì¼)
"""
    
    print("\nâœ… ì¢…í•© ë¦¬í¬íŠ¸ ë°ì´í„° ìƒì„± ì™„ë£Œ!")
    return comprehensive_context


def get_kospi_top_100_companies():
    """
    ì½”ìŠ¤í”¼ ìƒìœ„ 100ê°œ ê¸°ì—… ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    (ì‹œê°€ì´ì•¡ ê¸°ì¤€ ëŒ€ëµì ì¸ ìˆœì„œ, 2024ë…„ ê¸°ì¤€)
    
    Returns:
        List[str]: ì½”ìŠ¤í”¼ ìƒìœ„ 100ê°œ ê¸°ì—…ëª… ë¦¬ìŠ¤íŠ¸
    """
    kospi_top_100 = [
        # Top 10
        "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤", "NAVER", "ì¹´ì¹´ì˜¤", "LGì—ë„ˆì§€ì†”ë£¨ì…˜",
        "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤", "í˜„ëŒ€ìë™ì°¨", "ê¸°ì•„", "ì‚¼ì„±SDI", "LGí™”í•™",
        
        # 11-20
        "POSCOí™€ë”©ìŠ¤", "ì‚¼ì„±ë¬¼ì‚°", "KBê¸ˆìœµ", "ì‹ í•œì§€ì£¼", "í•˜ë‚˜ê¸ˆìœµì§€ì£¼",
        "LGì „ì", "í˜„ëŒ€ëª¨ë¹„ìŠ¤", "ì…€íŠ¸ë¦¬ì˜¨", "SKì´ë…¸ë² ì´ì…˜", "ì‚¼ì„±ìƒëª…ë³´í—˜",
        
        # 21-30
        "í•œêµ­ì „ë ¥ê³µì‚¬", "SKí…”ë ˆì½¤", "í¬ìŠ¤ì½”í“¨ì²˜ì— ", "í˜„ëŒ€ì¤‘ê³µì—…", "ì‚¼ì„±í™”ì¬",
        "LGìƒí™œê±´ê°•", "KT&G", "í•œí™”ì†”ë£¨ì…˜", "ê³ ë ¤ì•„ì—°", "ì‚¼ì„±ì—ìŠ¤ë””ì—ìŠ¤",
        
        # 31-40
        "ì•„ëª¨ë ˆí¼ì‹œí”½", "SK", "ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°", "HMM", "í•œêµ­ì¡°ì„ í•´ì–‘",
        "ê¸°ì—…ì€í–‰", "ìš°ë¦¬ê¸ˆìœµì§€ì£¼", "í˜„ëŒ€ê±´ì„¤", "ì‚¼ì„±ì „ê¸°", "LGì´ë…¸í…",
        
        # 41-50
        "KT", "í•œêµ­ê°€ìŠ¤ê³µì‚¬", "ë¡¯ë°ì¼€ë¯¸ì¹¼", "í˜„ëŒ€ê¸€ë¡œë¹„ìŠ¤", "SKìŠ¤í€˜ì–´",
        "í•œë¯¸ë°˜ë„ì²´", "ì‚¼ì„±ì¤‘ê³µì—…", "í¬ìŠ¤ì½”ì¸í„°ë‚´ì…”ë„", "ë‘ì‚°", "í˜„ëŒ€ì œì² ",
        
        # 51-60
        "LG", "í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤", "KBêµ­ë¯¼ì€í–‰", "ì‹ í•œì€í–‰", "í•˜ë‚˜ì€í–‰",
        "ì½”ì›¨ì´", "í¬ë˜í”„í†¤", "í„ì–´ë¹„ìŠ¤", "NCSoft", "ë„·ë§ˆë¸”",
        
        # 61-70
        "ì¹´ì¹´ì˜¤ë±…í¬", "ì¹´ì¹´ì˜¤í˜ì´", "ì»´íˆ¬ìŠ¤", "ìœ„ë©”ì´ë“œ", "ë„¥ìŠ¨ê²Œì„ì¦ˆ",
        "ì‚¼ì²œë¦¬", "GS", "GSì¹¼í…ìŠ¤", "S-Oil", "í˜„ëŒ€ì˜¤ì¼ë±…í¬",
        
        # 71-80
        "ë¡¯ë°ì‡¼í•‘", "ë¡¯ë°ì¹ ì„±ìŒë£Œ", "ì‹ ì„¸ê³„", "ì´ë§ˆíŠ¸", "í™ˆí”ŒëŸ¬ìŠ¤",
        "CJì œì¼ì œë‹¹", "CJ ENM", "CJëŒ€í•œí†µìš´", "ë™ì›ì‹œìŠ¤í…œì¦ˆ", "ì˜¤ëšœê¸°",
        
        # 81-90
        "ë†ì‹¬", "ë¡¯ë°ì œê³¼", "í•œí™”ì‹œìŠ¤í…œ", "í•œí™”ìƒëª…", "ë™í™”ì•½í’ˆ",
        "ìœ í•œì–‘í–‰", "ë…¹ì‹­ì", "ì…€íŠ¸ë¦¬ì˜¨ì œì•½", "ëŒ€ì›…ì œì•½", "ì¢…ê·¼ë‹¹",
        
        # 91-100
        "ì‚¼ì„±ë¬¼ì‚°", "í¬ìŠ¤ì½”DX", "SKë¨¸í‹°ë¦¬ì–¼ì¦ˆ", "LGë””ìŠ¤í”Œë ˆì´", "ì‚¼ì„±ë””ìŠ¤í”Œë ˆì´",
        "SKë°”ì´ì˜¤íŒœ", "í•œë¯¸ì•½í’ˆ", "ì¼ë™ì œì•½", "ë¶€ê´‘ì•½í’ˆ", "ëŒ€í•œí•­ê³µ"
    ]
    
    # ì¤‘ë³µ ì œê±° ë° ì •í™•í•œ 100ê°œë¡œ ì¡°ì •
    unique_companies = list(dict.fromkeys(kospi_top_100))  # ìˆœì„œ ìœ ì§€í•˜ë©´ì„œ ì¤‘ë³µ ì œê±°
    
    if len(unique_companies) > 100:
        unique_companies = unique_companies[:100]
    
    print(f"ğŸ“ˆ ì½”ìŠ¤í”¼ ìƒìœ„ {len(unique_companies)}ê°œ ê¸°ì—… ëª©ë¡ ë¡œë“œ ì™„ë£Œ")
    return unique_companies


def get_custom_company_list(list_type="top_10"):
    """
    ë‹¤ì–‘í•œ ê¸°ì—… ëª©ë¡ì„ ì œê³µí•˜ëŠ” í•¨ìˆ˜
    
    Args:
        list_type (str): ëª©ë¡ ìœ í˜•
            - "top_10": ìƒìœ„ 10ê°œ ê¸°ì—…
            - "top_30": ìƒìœ„ 30ê°œ ê¸°ì—…  
            - "top_50": ìƒìœ„ 50ê°œ ê¸°ì—…
            - "top_100": ìƒìœ„ 100ê°œ ê¸°ì—…
            - "tech_focus": ê¸°ìˆ ì£¼ ì¤‘ì‹¬
            - "finance_focus": ê¸ˆìœµì£¼ ì¤‘ì‹¬
            
    Returns:
        List[str]: ì„ íƒëœ ê¸°ì—… ëª©ë¡
    """
    kospi_100 = get_kospi_top_100_companies()
    
    if list_type == "top_10":
        return kospi_100[:10]
    elif list_type == "top_30":
        return kospi_100[:30]
    elif list_type == "top_50":
        return kospi_100[:50]
    elif list_type == "top_100":
        return kospi_100
    elif list_type == "tech_focus":
        tech_companies = [
            "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤", "NAVER", "ì¹´ì¹´ì˜¤", "LGì—ë„ˆì§€ì†”ë£¨ì…˜",
            "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤", "ì‚¼ì„±SDI", "LGí™”í•™", "LGì „ì", "ì…€íŠ¸ë¦¬ì˜¨",
            "ì‚¼ì„±ì—ìŠ¤ë””ì—ìŠ¤", "ì‚¼ì„±ì „ê¸°", "LGì´ë…¸í…", "í•œë¯¸ë°˜ë„ì²´", "ì½”ì›¨ì´",
            "í¬ë˜í”„í†¤", "í„ì–´ë¹„ìŠ¤", "NCSoft", "ë„·ë§ˆë¸”", "ì»´íˆ¬ìŠ¤"
        ]
        return tech_companies
    elif list_type == "finance_focus":
        finance_companies = [
            "KBê¸ˆìœµ", "ì‹ í•œì§€ì£¼", "í•˜ë‚˜ê¸ˆìœµì§€ì£¼", "ê¸°ì—…ì€í–‰", "ìš°ë¦¬ê¸ˆìœµì§€ì£¼",
            "KBêµ­ë¯¼ì€í–‰", "ì‹ í•œì€í–‰", "í•˜ë‚˜ì€í–‰", "ì¹´ì¹´ì˜¤ë±…í¬", "ì¹´ì¹´ì˜¤í˜ì´",
            "ì‚¼ì„±ìƒëª…ë³´í—˜", "ì‚¼ì„±í™”ì¬", "í•œí™”ìƒëª…"
        ]
        return finance_companies
    else:
        print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” list_type: {list_type}")
        return kospi_100[:10]  # ê¸°ë³¸ê°’


def save_company_list_to_file(companies, filename="target_companies.json"):
    """
    ê¸°ì—… ëª©ë¡ì„ JSON íŒŒì¼ë¡œ ì €ì¥
    
    Args:
        companies (List[str]): ê¸°ì—… ëª©ë¡
        filename (str): ì €ì¥í•  íŒŒì¼ëª…
    """
    company_data = {
        "created_at": datetime.now().isoformat(),
        "total_companies": len(companies),
        "companies": companies
    }
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(company_data, f, ensure_ascii=False, indent=2)
        print(f"âœ… ê¸°ì—… ëª©ë¡ ì €ì¥ ì™„ë£Œ: {filename} ({len(companies)}ê°œ ê¸°ì—…)")
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")


def load_company_list_from_file(filename="target_companies.json"):
    """
    JSON íŒŒì¼ì—ì„œ ê¸°ì—… ëª©ë¡ì„ ë¡œë“œ
    
    Args:
        filename (str): ë¡œë“œí•  íŒŒì¼ëª…
        
    Returns:
        List[str]: ê¸°ì—… ëª©ë¡
    """
    try:
        if not os.path.exists(filename):
            print(f"âŒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {filename}")
            return []
            
        with open(filename, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        companies = data.get('companies', [])
        created_at = data.get('created_at', '')
        
        print(f"âœ… ê¸°ì—… ëª©ë¡ ë¡œë“œ ì™„ë£Œ: {len(companies)}ê°œ ê¸°ì—… (ìƒì„±ì¼: {created_at[:10]})")
        return companies
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []
